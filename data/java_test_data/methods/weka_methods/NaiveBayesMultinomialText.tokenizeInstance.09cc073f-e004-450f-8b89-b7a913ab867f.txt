protected void tokenizeInstance(Instance instance, boolean updateDictionary) {
    if (m_inputVector == null) {
        m_inputVector = new LinkedHashMap<String, Count>();
    } else {
        m_inputVector.clear();
    }
    for (int i = 0; i < instance.numAttributes(); i++) {
        if (instance.attribute(i).isString() && !instance.isMissing(i)) {
            m_tokenizer.tokenize(instance.stringValue(i));
            while (m_tokenizer.hasMoreElements()) {
                String word = m_tokenizer.nextElement();
                if (m_lowercaseTokens) {
                    word = word.toLowerCase();
                }
                word = m_stemmer.stem(word);
                if (m_StopwordsHandler.isStopword(word)) {
                    continue;
                }
                Count docCount = m_inputVector.get(word);
                if (docCount == null) {
                    m_inputVector.put(word, new Count(instance.weight()));
                } else {
                    docCount.m_count += instance.weight();
                }
            }
        }
    }
    if (updateDictionary) {
        int classValue = (int) instance.classValue();
        LinkedHashMap<String, Count> dictForClass = m_probOfWordGivenClass.get(classValue);
        // document normalization
        double iNorm = 0;
        double fv = 0;
        if (m_normalize) {
            for (Count c : m_inputVector.values()) {
                // word counts or bag-of-words?
                fv = (m_wordFrequencies) ? c.m_count : 1.0;
                iNorm += Math.pow(Math.abs(fv), m_lnorm);
            }
            iNorm = Math.pow(iNorm, 1.0 / m_lnorm);
        }
        for (Map.Entry<String, Count> feature : m_inputVector.entrySet()) {
            String word = feature.getKey();
            double freq = (m_wordFrequencies) ? feature.getValue().m_count : 1.0;
            if (m_normalize) {
                freq *= (m_norm / iNorm);
            }
            // check all classes
            for (int i = 0; i < m_data.numClasses(); i++) {
                LinkedHashMap<String, Count> dict = m_probOfWordGivenClass.get(i);
                if (dict.get(word) == null) {
                    dict.put(word, new Count(m_leplace));
                    m_wordsPerClass[i] += m_leplace;
                }
            }
            Count dictCount = dictForClass.get(word);
            /*
         * if (dictCount == null) { dictForClass.put(word, new Count(m_leplace +
         * freq)); m_wordsPerClass[classValue] += (m_leplace + freq); } else {
         */
            dictCount.m_count += freq;
            m_wordsPerClass[classValue] += freq;
        // }
        }
        pruneDictionary(false);
    }
}
