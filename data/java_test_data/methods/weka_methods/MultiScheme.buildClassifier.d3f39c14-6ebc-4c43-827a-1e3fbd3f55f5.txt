public void buildClassifier(Instances data) throws Exception {
    if (m_Classifiers.length == 0) {
        throw new Exception("No base classifiers have been set!");
    }
    // can classifier handle the data?
    getCapabilities().testWithFail(data);
    // remove instances with missing class
    Instances newData = new Instances(data);
    newData.deleteWithMissingClass();
    Random random = new Random(m_Seed);
    newData.randomize(random);
    if (newData.classAttribute().isNominal() && (m_NumXValFolds > 1)) {
        newData.stratify(m_NumXValFolds);
    }
    // train on all data by default
    Instances train = newData;
    // test on training data by default
    Instances test = newData;
    Classifier bestClassifier = null;
    int bestIndex = -1;
    double bestPerformance = Double.NaN;
    int numClassifiers = m_Classifiers.length;
    for (int i = 0; i < numClassifiers; i++) {
        Classifier currentClassifier = getClassifier(i);
        Evaluation evaluation;
        if (m_NumXValFolds > 1) {
            evaluation = new Evaluation(newData);
            for (int j = 0; j < m_NumXValFolds; j++) {
                // We want to randomize the data the same way for every
                // learning scheme.
                train = newData.trainCV(m_NumXValFolds, j, new Random(1));
                test = newData.testCV(m_NumXValFolds, j);
                currentClassifier.buildClassifier(train);
                evaluation.setPriors(train);
                evaluation.evaluateModel(currentClassifier, test);
            }
        } else {
            currentClassifier.buildClassifier(train);
            evaluation = new Evaluation(train);
            evaluation.evaluateModel(currentClassifier, test);
        }
        double error = evaluation.errorRate();
        if (m_Debug) {
            System.err.println("Error rate: " + Utils.doubleToString(error, 6, 4) + " for classifier " + currentClassifier.getClass().getName());
        }
        if ((i == 0) || (error < bestPerformance)) {
            bestClassifier = currentClassifier;
            bestPerformance = error;
            bestIndex = i;
        }
    }
    m_ClassifierIndex = bestIndex;
    if (m_NumXValFolds > 1) {
        bestClassifier.buildClassifier(newData);
    }
    m_Classifier = bestClassifier;
}
