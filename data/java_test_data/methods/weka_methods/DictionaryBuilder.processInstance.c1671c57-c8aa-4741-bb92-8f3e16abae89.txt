public void processInstance(Instance inst) {
    if (!m_inputContainsStringAttributes) {
        return;
    }
    if (m_inputVector == null) {
        m_inputVector = new LinkedHashMap<String, int[]>();
    } else {
        m_inputVector.clear();
    }
    int dIndex = 0;
    if (!m_doNotOperateOnPerClassBasis && m_classIndex >= 0 && m_inputFormat.classAttribute().isNominal()) {
        if (!inst.classIsMissing()) {
            dIndex = (int) inst.classValue();
        } else {
            // skip missing class instances
            return;
        }
    }
    for (int j = 0; j < inst.numAttributes(); j++) {
        if (m_selectedRange.isInRange(j) && !inst.isMissing(j)) {
            m_tokenizer.tokenize(inst.stringValue(j));
            while (m_tokenizer.hasMoreElements()) {
                String word = m_tokenizer.nextElement();
                if (m_lowerCaseTokens) {
                    word = word.toLowerCase();
                }
                word = m_stemmer.stem(word);
                if (m_stopwordsHandler.isStopword(word)) {
                    continue;
                }
                int[] counts = m_inputVector.get(word);
                if (counts == null) {
                    counts = new int[2];
                    // word count
                    counts[0] = 1;
                    // doc count
                    counts[1] = 1;
                    m_inputVector.put(word, counts);
                } else {
                    counts[0]++;
                }
            }
        }
    }
    // now update dictionary for the words that have
    // occurred in this instance (document)
    double docLength = 0;
    for (Map.Entry<String, int[]> e : m_inputVector.entrySet()) {
        int[] dictCounts = m_dictsPerClass[dIndex].get(e.getKey());
        if (dictCounts == null) {
            dictCounts = new int[2];
            m_dictsPerClass[dIndex].put(e.getKey(), dictCounts);
        }
        dictCounts[0] += e.getValue()[0];
        dictCounts[1] += e.getValue()[1];
        docLength += e.getValue()[0] * e.getValue()[0];
    }
    if (m_normalize) {
        // this is normalization based document length *before* final dictionary
        // pruning. DictionaryBuilder operates incrementally, so it is not
        // possible to normalize based on a final dictionary
        m_docLengthSum += Math.sqrt(docLength);
    }
    m_count++;
    pruneDictionary();
}
