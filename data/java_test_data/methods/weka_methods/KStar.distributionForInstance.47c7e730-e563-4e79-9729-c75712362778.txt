public double[] distributionForInstance(Instance instance) throws Exception {
    double transProb = 0.0, temp = 0.0;
    double[] classProbability = new double[m_NumClasses];
    double[] predictedValue = new double[1];
    // initialization ...
    for (int i = 0; i < classProbability.length; i++) {
        classProbability[i] = 0.0;
    }
    predictedValue[0] = 0.0;
    if (m_InitFlag == ON) {
        // We are doing this because the evaluation module controls the calls.
        if (m_BlendMethod == B_ENTROPY) {
            generateRandomClassColomns();
        }
        m_Cache = new KStarCache[m_NumAttributes];
        for (int i = 0; i < m_NumAttributes; i++) {
            m_Cache[i] = new KStarCache();
        }
        m_InitFlag = OFF;
    // System.out.println("Computing...");
    }
    // init done.
    Instance trainInstance;
    Enumeration<Instance> enu = m_Train.enumerateInstances();
    while (enu.hasMoreElements()) {
        trainInstance = (Instance) enu.nextElement();
        transProb = instanceTransformationProbability(instance, trainInstance);
        switch(m_ClassType) {
            case Attribute.NOMINAL:
                classProbability[(int) trainInstance.classValue()] += transProb;
                break;
            case Attribute.NUMERIC:
                predictedValue[0] += transProb * trainInstance.classValue();
                temp += transProb;
                break;
        }
    }
    if (m_ClassType == Attribute.NOMINAL) {
        double sum = Utils.sum(classProbability);
        if (sum <= 0.0)
            for (int i = 0; i < classProbability.length; i++) classProbability[i] = (double) 1 / (double) m_NumClasses;
        else
            Utils.normalize(classProbability, sum);
        return classProbability;
    } else {
        predictedValue[0] = (temp != 0) ? predictedValue[0] / temp : 0.0;
        return predictedValue;
    }
}
