protected void updateClassifier(Instance instance, boolean updateDictionary) throws Exception {
    if (!instance.classIsMissing()) {
        // tokenize
        tokenizeInstance(instance, updateDictionary);
        // the SVM
        if (m_loss == HINGE && m_fitLogistic) {
            double pred = svmOutput();
            double[] vals = new double[2];
            vals[0] = pred;
            vals[1] = instance.classValue();
            DenseInstance metaI = new DenseInstance(instance.weight(), vals);
            metaI.setDataset(m_fitLogisticStructure);
            m_svmProbs.updateClassifier(metaI);
        }
        // ---
        double wx = dotProd(m_inputVector);
        double y = (instance.classValue() == 0) ? -1 : 1;
        double z = y * (wx + m_bias);
        // Compute multiplier for weight decay
        double multiplier = 1.0;
        if (m_numInstances == 0) {
            multiplier = 1.0 - (m_learningRate * m_lambda) / m_t;
        } else {
            multiplier = 1.0 - (m_learningRate * m_lambda) / m_numInstances;
        }
        for (Map.Entry<String, Count> c : m_dictionary.entrySet()) {
            c.getValue().m_weight *= multiplier;
        }
        // Only need to do the following if the loss is non-zero
        if (m_loss != HINGE || (z < 1)) {
            // Compute Factor for updates
            double dloss = dloss(z);
            double factor = m_learningRate * y * dloss;
            // Update coefficients for attributes
            for (Map.Entry<String, Count> feature : m_inputVector.entrySet()) {
                String word = feature.getKey();
                double value = (m_wordFrequencies) ? feature.getValue().m_count : 1;
                Count c = m_dictionary.get(word);
                if (c != null) {
                    c.m_weight += factor * value;
                }
            }
            // update the bias
            m_bias += factor;
        }
        m_t++;
    }
}
