private void updateWeightsDiscreteClass(int instNum) {
    int i, j, k;
    int cl;
    double temp_diff, w_norm = 1.0;
    double[] tempDistClass;
    int[] tempSortedClass = null;
    double distNormClass = 1.0;
    double[] tempDistAtt;
    int[][] tempSortedAtt = null;
    double[] distNormAtt = null;
    int firstI, secondI;
    // store the indexes (sparse instances) of non-zero elements
    Instance inst = m_trainInstances.instance(instNum);
    // get the class of this instance
    cl = (int) m_trainInstances.instance(instNum).value(m_classIndex);
    // sort nearest neighbours and set up normalization variables
    if (m_weightByDistance) {
        // do class (hits) first
        // sort the distances
        tempDistClass = new double[m_stored[cl]];
        for (j = 0, distNormClass = 0; j < m_stored[cl]; j++) {
            // copy the distances
            tempDistClass[j] = m_karray[cl][j][0];
            // sum normalizer
            distNormClass += m_weightsByRank[j];
        }
        tempSortedClass = Utils.sort(tempDistClass);
        // do misses (other classes)
        tempSortedAtt = new int[m_numClasses][1];
        distNormAtt = new double[m_numClasses];
        for (k = 0; k < m_numClasses; k++) {
            if (// already done cl
            k != cl) {
                // sort the distances
                tempDistAtt = new double[m_stored[k]];
                for (j = 0, distNormAtt[k] = 0; j < m_stored[k]; j++) {
                    // copy the distances
                    tempDistAtt[j] = m_karray[k][j][0];
                    // sum normalizer
                    distNormAtt[k] += m_weightsByRank[j];
                }
                tempSortedAtt[k] = Utils.sort(tempDistAtt);
            }
        }
    }
    if (m_numClasses > 2) {
        // the amount of probability space left after removing the
        // probability of this instance's class value
        w_norm = (1.0 - m_classProbs[cl]);
    }
    // do the k nearest hits of the same class
    for (j = 0, temp_diff = 0.0; j < m_stored[cl]; j++) {
        Instance cmp;
        cmp = (m_weightByDistance) ? m_trainInstances.instance((int) m_karray[cl][tempSortedClass[j]][1]) : m_trainInstances.instance((int) m_karray[cl][j][1]);
        for (int p1 = 0, p2 = 0; p1 < inst.numValues() || p2 < cmp.numValues(); ) {
            if (p1 >= inst.numValues()) {
                firstI = m_trainInstances.numAttributes();
            } else {
                firstI = inst.index(p1);
            }
            if (p2 >= cmp.numValues()) {
                secondI = m_trainInstances.numAttributes();
            } else {
                secondI = cmp.index(p2);
            }
            if (firstI == m_trainInstances.classIndex()) {
                p1++;
                continue;
            }
            if (secondI == m_trainInstances.classIndex()) {
                p2++;
                continue;
            }
            if (firstI == secondI) {
                i = firstI;
                temp_diff = difference(i, inst.valueSparse(p1), cmp.valueSparse(p2));
                p1++;
                p2++;
            } else if (firstI > secondI) {
                i = secondI;
                temp_diff = difference(i, 0, cmp.valueSparse(p2));
                p2++;
            } else {
                i = firstI;
                temp_diff = difference(i, inst.valueSparse(p1), 0);
                p1++;
            }
            if (m_weightByDistance) {
                temp_diff *= (m_weightsByRank[j] / distNormClass);
            } else {
                if (m_stored[cl] > 0) {
                    temp_diff /= m_stored[cl];
                }
            }
            m_weights[i] -= temp_diff;
        }
    }
    // now do k nearest misses from each of the other classes
    temp_diff = 0.0;
    for (k = 0; k < m_numClasses; k++) {
        if (// already done cl
        k != cl) {
            for (j = 0; j < m_stored[k]; j++) {
                Instance cmp;
                cmp = (m_weightByDistance) ? m_trainInstances.instance((int) m_karray[k][tempSortedAtt[k][j]][1]) : m_trainInstances.instance((int) m_karray[k][j][1]);
                for (int p1 = 0, p2 = 0; p1 < inst.numValues() || p2 < cmp.numValues(); ) {
                    if (p1 >= inst.numValues()) {
                        firstI = m_trainInstances.numAttributes();
                    } else {
                        firstI = inst.index(p1);
                    }
                    if (p2 >= cmp.numValues()) {
                        secondI = m_trainInstances.numAttributes();
                    } else {
                        secondI = cmp.index(p2);
                    }
                    if (firstI == m_trainInstances.classIndex()) {
                        p1++;
                        continue;
                    }
                    if (secondI == m_trainInstances.classIndex()) {
                        p2++;
                        continue;
                    }
                    if (firstI == secondI) {
                        i = firstI;
                        temp_diff = difference(i, inst.valueSparse(p1), cmp.valueSparse(p2));
                        p1++;
                        p2++;
                    } else if (firstI > secondI) {
                        i = secondI;
                        temp_diff = difference(i, 0, cmp.valueSparse(p2));
                        p2++;
                    } else {
                        i = firstI;
                        temp_diff = difference(i, inst.valueSparse(p1), 0);
                        p1++;
                    }
                    if (m_weightByDistance) {
                        temp_diff *= (m_weightsByRank[j] / distNormAtt[k]);
                    } else {
                        if (m_stored[k] > 0) {
                            temp_diff /= m_stored[k];
                        }
                    }
                    if (m_numClasses > 2) {
                        m_weights[i] += ((m_classProbs[k] / w_norm) * temp_diff);
                    } else {
                        m_weights[i] += temp_diff;
                    }
                }
            }
        }
    }
}
