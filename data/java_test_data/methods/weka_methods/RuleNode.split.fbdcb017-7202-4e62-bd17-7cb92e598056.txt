public void split() throws Exception {
    int i;
    Instances leftSubset, rightSubset;
    SplitEvaluate bestSplit, currentSplit;
    boolean[] attsBelow;
    if (!m_isLeaf) {
        bestSplit = new YongSplitInfo(0, m_numInstances - 1, -1);
        currentSplit = new YongSplitInfo(0, m_numInstances - 1, -1);
        // find the best attribute to split on
        for (i = 0; i < m_numAttributes; i++) {
            if (i != m_classIndex) {
                // sort the instances by this attribute
                m_instances.sort(i);
                currentSplit.attrSplit(i, m_instances);
                if ((Math.abs(currentSplit.maxImpurity() - bestSplit.maxImpurity()) > 1.e-6) && (currentSplit.maxImpurity() > bestSplit.maxImpurity() + 1.e-6)) {
                    bestSplit = currentSplit.copy();
                }
            }
        }
        // cant find a good split or split point?
        if (bestSplit.splitAttr() < 0 || bestSplit.position() < 1 || bestSplit.position() > m_numInstances - 1) {
            m_isLeaf = true;
        } else {
            m_splitAtt = bestSplit.splitAttr();
            m_splitValue = bestSplit.splitValue();
            leftSubset = new Instances(m_instances, m_numInstances);
            rightSubset = new Instances(m_instances, m_numInstances);
            for (i = 0; i < m_numInstances; i++) {
                if (m_instances.instance(i).value(m_splitAtt) <= m_splitValue) {
                    leftSubset.add(m_instances.instance(i));
                } else {
                    rightSubset.add(m_instances.instance(i));
                }
            }
            leftSubset.compactify();
            rightSubset.compactify();
            // build left and right nodes
            m_left = new RuleNode(m_globalDeviation, m_globalAbsDeviation, this);
            m_left.setMinNumInstances(m_splitNum);
            m_left.setRegressionTree(m_regressionTree);
            m_left.setSaveInstances(m_saveInstances);
            m_left.buildClassifier(leftSubset);
            m_right = new RuleNode(m_globalDeviation, m_globalAbsDeviation, this);
            m_right.setMinNumInstances(m_splitNum);
            m_right.setRegressionTree(m_regressionTree);
            m_right.setSaveInstances(m_saveInstances);
            m_right.buildClassifier(rightSubset);
            // subtrees and use them to learn a linear model for this node
            if (!m_regressionTree) {
                attsBelow = attsTestedBelow();
                attsBelow[m_classIndex] = true;
                int count = 0, j;
                for (j = 0; j < m_numAttributes; j++) {
                    if (attsBelow[j]) {
                        count++;
                    }
                }
                int[] indices = new int[count];
                count = 0;
                for (j = 0; j < m_numAttributes; j++) {
                    if (attsBelow[j] && (j != m_classIndex)) {
                        indices[count++] = j;
                    }
                }
                indices[count] = m_classIndex;
                m_indices = indices;
            } else {
                m_indices = new int[1];
                m_indices[0] = m_classIndex;
                m_numParameters = 1;
            }
        }
    }
    if (m_isLeaf) {
        int[] indices = new int[1];
        indices[0] = m_classIndex;
        m_indices = indices;
        m_numParameters = 1;
    // need to evaluate the model here if want correct stats for unpruned
    // tree
    }
}
