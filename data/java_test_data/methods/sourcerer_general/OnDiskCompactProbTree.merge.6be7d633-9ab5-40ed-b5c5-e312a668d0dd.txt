public static OnDiskCompactProbTree merge(OnDiskCompactProbTree t1, OnDiskCompactProbTree t2) {
    long start = Timing.nanoTime();
    try {
        if (t1.getSize() < t2.getSize()) {
            OnDiskCompactProbTree tmp = t1;
            t1 = t2;
            t2 = tmp;
        }
        if (t2.scale == 0) {
            return (OnDiskCompactProbTree) t1.clone();
        } else if (t1.scale == 0) {
            return (OnDiskCompactProbTree) t2.clone();
        }
        // at this point, t1 is the bigger tree
        // normally this also means that it includes all elements from the smaller tree
        // as t1 would represent the distribution at the parent node in the decision tree
        OnDiskCompactProbTree result = new OnDiskCompactProbTree(t1.getSize());
        final int size1 = t1.getSize();
        final int size2 = t2.getSize();
        final int[] factors1 = t1.compactHiddenFactors;
        final int[] factors2 = t2.compactHiddenFactors;
        final double scale2 = (t2.scale / t1.scale);
        int point1 = 0;
        int point2 = 0;
        int out = 0;
        while (point1 < size1 || point2 < size2) {
            if (out == result.compactHiddenFactors.length) {
                result.grow(out + Math.max(size1 - point1, size2 - point2));
            }
            if (point2 == size2) {
                result.compactHiddenFactors[out] = factors1[point1];
                result.probabilities[out] = t1.probabilities[point1];
                point1++;
            } else if (point1 < size1) {
                if (factors1[point1] < factors2[point2]) {
                    result.compactHiddenFactors[out] = factors1[point1];
                    result.probabilities[out] = t1.probabilities[point1];
                    point1++;
                } else if (factors1[point1] == factors2[point2]) {
                    result.compactHiddenFactors[out] = factors2[point2];
                    result.probabilities[out] = (float) (t1.probabilities[point1] + t2.probabilities[point2] * scale2);
                    point1++;
                    point2++;
                } else {
                    result.compactHiddenFactors[out] = factors2[point2];
                    result.probabilities[out] = (float) (t2.probabilities[point2] * scale2);
                    point2++;
                }
            } else {
                // point1 == size1 && point2 < size2
                result.compactHiddenFactors[out] = factors2[point2];
                result.probabilities[out] = (float) (t2.probabilities[point2] * scale2);
                point2++;
            }
            out++;
        }
        result.size = (short) out;
        result.scale = t1.scale;
        return result;
    } finally {
        long end = Timing.nanoTime();
        ProbTree.totalLeafyMergeCount += 1;
        ProbTree.totalLeafyMergeTime += end - start;
    }
}
