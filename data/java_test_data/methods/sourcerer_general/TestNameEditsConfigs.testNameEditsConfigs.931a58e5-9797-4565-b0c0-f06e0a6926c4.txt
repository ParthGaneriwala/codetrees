public void testNameEditsConfigs() throws IOException {
    Path file1 = new Path("TestNameEditsConfigs1");
    Path file2 = new Path("TestNameEditsConfigs2");
    Path file3 = new Path("TestNameEditsConfigs3");
    MiniDFSCluster cluster = null;
    SecondaryNameNode secondary = null;
    Configuration conf = null;
    FileSystem fileSys = null;
    File base_dir = new File(System.getProperty("test.build.data"), "dfs/");
    File newNameDir = new File(base_dir, "name");
    File newEditsDir = new File(base_dir, "edits");
    File nameAndEdits = new File(base_dir, "name_and_edits");
    File checkpointNameDir = new File(base_dir, "secondname");
    File checkpointEditsDir = new File(base_dir, "secondedits");
    File checkpointNameAndEdits = new File(base_dir, "second_name_and_edits");
    // Start namenode with same dfs.name.dir and dfs.name.edits.dir
    conf = new Configuration();
    conf.set("dfs.name.dir", nameAndEdits.getPath());
    conf.set("dfs.name.edits.dir", nameAndEdits.getPath());
    conf.set("fs.checkpoint.dir", checkpointNameAndEdits.getPath());
    conf.set("fs.checkpoint.edits.dir", checkpointNameAndEdits.getPath());
    replication = (short) conf.getInt("dfs.replication", 3);
    // Manage our own dfs directories
    cluster = new MiniDFSCluster(0, conf, numDatanodes, true, false, true, null, null, null, null);
    cluster.waitActive();
    secondary = startSecondaryNameNode(conf);
    fileSys = cluster.getFileSystem();
    try {
        assertTrue(!fileSys.exists(file1));
        writeFile(fileSys, file1, replication);
        checkFile(fileSys, file1, replication);
        secondary.doCheckpoint();
    } finally {
        fileSys.close();
        cluster.shutdown();
        secondary.shutdown();
    }
    // Start namenode with additional dfs.name.dir and dfs.name.edits.dir
    conf = new Configuration();
    assertTrue(newNameDir.mkdir());
    assertTrue(newEditsDir.mkdir());
    conf.set("dfs.name.dir", nameAndEdits.getPath() + "," + newNameDir.getPath());
    conf.set("dfs.name.edits.dir", nameAndEdits.getPath() + "," + newEditsDir.getPath());
    conf.set("fs.checkpoint.dir", checkpointNameDir.getPath() + "," + checkpointNameAndEdits.getPath());
    conf.set("fs.checkpoint.edits.dir", checkpointEditsDir.getPath() + "," + checkpointNameAndEdits.getPath());
    replication = (short) conf.getInt("dfs.replication", 3);
    // Manage our own dfs directories. Do not format.
    cluster = new MiniDFSCluster(0, conf, numDatanodes, false, false, true, null, null, null, null);
    cluster.waitActive();
    secondary = startSecondaryNameNode(conf);
    fileSys = cluster.getFileSystem();
    try {
        assertTrue(fileSys.exists(file1));
        checkFile(fileSys, file1, replication);
        cleanupFile(fileSys, file1);
        writeFile(fileSys, file2, replication);
        checkFile(fileSys, file2, replication);
        secondary.doCheckpoint();
    } finally {
        fileSys.close();
        cluster.shutdown();
        secondary.shutdown();
    }
    // Now remove common directory both have and start namenode with
    // separate name and edits dirs
    conf = new Configuration();
    conf.set("dfs.name.dir", newNameDir.getPath());
    conf.set("dfs.name.edits.dir", newEditsDir.getPath());
    conf.set("fs.checkpoint.dir", checkpointNameDir.getPath());
    conf.set("fs.checkpoint.edits.dir", checkpointEditsDir.getPath());
    replication = (short) conf.getInt("dfs.replication", 3);
    cluster = new MiniDFSCluster(0, conf, numDatanodes, false, false, true, null, null, null, null);
    cluster.waitActive();
    secondary = startSecondaryNameNode(conf);
    fileSys = cluster.getFileSystem();
    try {
        assertTrue(!fileSys.exists(file1));
        assertTrue(fileSys.exists(file2));
        checkFile(fileSys, file2, replication);
        cleanupFile(fileSys, file2);
        writeFile(fileSys, file3, replication);
        checkFile(fileSys, file3, replication);
        secondary.doCheckpoint();
    } finally {
        fileSys.close();
        cluster.shutdown();
        secondary.shutdown();
    }
    // Add old name_and_edits dir. File system should not read image or edits
    // from old dir
    conf = new Configuration();
    conf.set("dfs.name.dir", nameAndEdits.getPath() + "," + newNameDir.getPath());
    conf.set("dfs.name.edits.dir", nameAndEdits + "," + newEditsDir.getPath());
    replication = (short) conf.getInt("dfs.replication", 3);
    cluster = new MiniDFSCluster(0, conf, numDatanodes, false, false, true, null, null, null, null);
    cluster.waitActive();
    fileSys = cluster.getFileSystem();
    try {
        assertTrue(!fileSys.exists(file1));
        assertTrue(!fileSys.exists(file2));
        assertTrue(fileSys.exists(file3));
        checkFile(fileSys, file3, replication);
    } finally {
        fileSys.close();
        cluster.shutdown();
    }
    // Cleanup
    if (!FileUtil.fullyDelete(newNameDir))
        throw new IOException("Cannot remove directory " + newNameDir);
    if (!FileUtil.fullyDelete(newEditsDir))
        throw new IOException("Cannot remove directory " + newEditsDir);
    if (!FileUtil.fullyDelete(nameAndEdits))
        throw new IOException("Cannot remove directory " + nameAndEdits);
    if (!FileUtil.fullyDelete(checkpointNameDir))
        throw new IOException("Cannot remove directory " + checkpointNameDir);
    if (!FileUtil.fullyDelete(checkpointEditsDir))
        throw new IOException("Cannot remove directory " + checkpointEditsDir);
    if (!FileUtil.fullyDelete(checkpointNameAndEdits))
        throw new IOException("Cannot remove directory " + checkpointNameAndEdits);
}
