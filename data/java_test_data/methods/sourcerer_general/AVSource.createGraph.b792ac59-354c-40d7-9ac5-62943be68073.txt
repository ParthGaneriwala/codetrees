public void createGraph() {
    /**
     * TODO:
     * Change this to an (uncompressed PCM) audiofile on your machine! The demo uses standard javasound
     * functions to read from a file. You may change that to other sources in line 122.
     */
    java.io.File audioFile = new java.io.File(// "wav/VivaLasVegas44m.wav");
    "wav/VivaLasVegas32s.wav");
    try {
        audioInputStream = AudioSystem.getAudioInputStream(audioFile);
        AudioFormat format = audioInputStream.getFormat();
        SAMPLE_RATE = format.getSampleRate();
        BITS = format.getSampleSizeInBits();
        CHANNELS = format.getChannels();
        System.out.println("audiofile: " + audioFile.getName() + "\n" + "sampleRate: " + SAMPLE_RATE + "\n" + "bits: " + BITS + "\n" + "channels: " + CHANNELS + "\n" + "frameSize: " + format.getFrameSize() + "\n" + "frameRate: " + format.getFrameRate());
    } catch (Exception e) {
        System.out.println("error loading audio file");
        return;
    }
    f = new javax.swing.JFrame("dsj_AVSource");
    f.setLayout(new java.awt.BorderLayout());
    graph = DSGraph.createFilterGraph(DSFiltergraph.JAVA_POLL | DSFiltergraph.INIT_PAUSED, this);
    startTime = System.currentTimeMillis();
    videoSourceFilter = graph.insertJavaSourceFilter(720, 480, FPS, SOURCE_FLAGS);
    g2d = videoSourceFilter.getDrawingSurface();
    g2d.setFont(new java.awt.Font("Arial", 1, 48));
    g2d.setColor(java.awt.Color.red);
    g2d.setBackground(Color.black);
    videoSourceFilter.renderPin(videoSourceFilter.getPin(0, 0));
    audioSourceFilter = graph.insertJavaAudioSource(BITS, CHANNELS, SAMPLE_RATE, JavaSourceFilter.BLOCKING, null, null);
    audioSourceFilter.renderPin(audioSourceFilter.getPin(0, 0));
    bufferSize = audioSourceFilter.getBufferSize();
    System.out.println("bufferSize: " + bufferSize);
    audioBytes = new byte[bufferSize];
    graph.setupComplete();
    f.add("Center", graph.asComponent());
    /**
     * figure out in which intervals DirectShow will want new data *
     */
    videoFrameTime = videoSourceFilter.getVideoFrameTime();
    audioFrameTime = audioSourceFilter.getAudioFrameTime();
    System.out.println("time per video frame: " + videoFrameTime);
    System.out.println("time per audio frame: " + audioFrameTime);
    /**
     * just for stop button & (preview & replay) volume ctrl *
     */
    smc = new SwingMovieController();
    smc.setFiltergraph(graph);
    f.add("South", smc);
    f.pack();
    f.setVisible(true);
    /**
     * If you break here you have a preview graph.
     *
     * We're going to tear down parts of the filtergraph to connect a filesink.
     * In BLOCKING mode the source filters should be stopped explicitly
     */
    videoSourceFilter.stop();
    audioSourceFilter.stop();
    /**
     * create and connect the sink *
     */
    setupFileRendering();
    if ((SOURCE_FLAGS & JavaSourceFilter.CALLBACK) == 0) {
        System.out.println("Rendering threaded for " + MAX_TIME + "msec");
        new Thread(new RenderThread()).start();
    } else
        System.out.println("Rendering " + MAX_FRAMES + " frames, callback driven");
    graph.play();
    f.addWindowListener(new java.awt.event.WindowAdapter() {

        public void windowClosing(java.awt.event.WindowEvent e) {
            try {
                videoSourceFilter.stop();
                audioSourceFilter.stop();
                graph.stop();
                graph.dispose();
            } catch (Exception ex) {
            }
            System.exit(0);
        }

        public void windowClosed(java.awt.event.WindowEvent e) {
            System.exit(0);
        }
    });
}
