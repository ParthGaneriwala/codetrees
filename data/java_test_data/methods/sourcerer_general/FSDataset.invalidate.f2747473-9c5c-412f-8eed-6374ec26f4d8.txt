public void invalidate(Block[] invalidBlks) throws IOException {
    boolean error = false;
    for (int i = 0; i < invalidBlks.length; i++) {
        File f = null;
        FSVolume v;
        synchronized (this) {
            f = getFile(invalidBlks[i]);
            DatanodeBlockInfo dinfo = volumeMap.get(invalidBlks[i]);
            if (dinfo == null) {
                DataNode.LOG.warn("Unexpected error trying to delete block " + invalidBlks[i] + ". BlockInfo not found in volumeMap.");
                error = true;
                continue;
            }
            v = dinfo.getVolume();
            if (f == null) {
                DataNode.LOG.warn("Unexpected error trying to delete block " + invalidBlks[i] + ". Block not found in blockMap." + ((v == null) ? " " : " Block found in volumeMap."));
                error = true;
                continue;
            }
            if (v == null) {
                DataNode.LOG.warn("Unexpected error trying to delete block " + invalidBlks[i] + ". No volume for this block." + " Block found in blockMap. " + f + ".");
                error = true;
                continue;
            }
            File parent = f.getParentFile();
            if (parent == null) {
                DataNode.LOG.warn("Unexpected error trying to delete block " + invalidBlks[i] + ". Parent not found for file " + f + ".");
                error = true;
                continue;
            }
            v.clearPath(parent);
            volumeMap.remove(invalidBlks[i]);
        }
        File metaFile = getMetaFile(f, invalidBlks[i]);
        long blockSize = f.length() + metaFile.length();
        if (!f.delete() || (!metaFile.delete() && metaFile.exists())) {
            DataNode.LOG.warn("Unexpected error trying to delete block " + invalidBlks[i] + " at file " + f);
            error = true;
            continue;
        }
        v.decDfsUsed(blockSize);
        DataNode.LOG.info("Deleting block " + invalidBlks[i] + " file " + f);
        if (f.exists()) {
            // 
            // This is a temporary check especially for org.fit.hiai.hadoop-1220.
            // This will go away in the future.
            // 
            DataNode.LOG.info("File " + f + " was deleted but still exists!");
        }
    }
    if (error) {
        throw new IOException("Error in deleting blocks.");
    }
}
