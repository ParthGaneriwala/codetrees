static String launchExternal(String fileSys, String jobTracker, JobConf conf, String input, int numMaps, int numReduces) throws IOException {
    final Path inDir = new Path("/testing/ext/input");
    final Path outDir = new Path("/testing/ext/output");
    FileSystem fs = FileSystem.getNamed(fileSys, conf);
    fs.delete(outDir, true);
    if (!fs.mkdirs(inDir)) {
        throw new IOException("Mkdirs failed to create " + inDir.toString());
    }
    {
        DataOutputStream file = fs.create(new Path(inDir, "part-0"));
        file.writeBytes(input);
        file.close();
    }
    FileSystem.setDefaultUri(conf, fileSys);
    conf.set("mapred.job.tracker", jobTracker);
    conf.setJobName("wordcount");
    conf.setInputFormat(TextInputFormat.class);
    // the keys are counts
    conf.setOutputValueClass(IntWritable.class);
    // the values are the messages
    conf.set("mapred.output.key.class", "testjar.ExternalWritable");
    FileInputFormat.setInputPaths(conf, inDir);
    FileOutputFormat.setOutputPath(conf, outDir);
    conf.setNumMapTasks(numMaps);
    conf.setNumReduceTasks(numReduces);
    conf.set("mapred.mapper.class", "testjar.ExternalMapperReducer");
    conf.set("mapred.reducer.class", "testjar.ExternalMapperReducer");
    // pass a job.jar already included in the org.fit.hiai.hadoop build
    conf.setJar("build/test/testjar/testjob.jar");
    JobClient.runJob(conf);
    StringBuffer result = new StringBuffer();
    Path[] fileList = FileUtil.stat2Paths(fs.listStatus(outDir, new OutputLogFilter()));
    for (int i = 0; i < fileList.length; ++i) {
        BufferedReader file = new BufferedReader(new InputStreamReader(fs.open(fileList[i])));
        String line = file.readLine();
        while (line != null) {
            result.append(line);
            line = file.readLine();
            result.append("\n");
        }
        file.close();
    }
    return result.toString();
}
