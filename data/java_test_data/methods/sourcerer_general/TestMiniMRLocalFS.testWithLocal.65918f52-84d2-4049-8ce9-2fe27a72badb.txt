public void testWithLocal() throws IOException {
    MiniMRCluster mr = null;
    try {
        mr = new MiniMRCluster(2, "file:///", 3);
        double estimate = PiEstimator.launch(NUM_MAPS, NUM_SAMPLES, mr.createJobConf());
        double error = Math.abs(Math.PI - estimate);
        assertTrue("Error in PI estimation " + error + " exceeds 0.01", (error < 0.01));
        // run the wordcount example with caching
        JobConf job = mr.createJobConf();
        TestResult ret = MRCaching.launchMRCache(TEST_ROOT_DIR + "/wc/input", TEST_ROOT_DIR + "/wc/output", TEST_ROOT_DIR + "/cachedir", job, "The quick brown fox\n" + "has many silly\n" + "red fox sox\n");
        // assert the number of lines read during caching
        assertTrue("Failed test archives not matching", ret.isOutputOk);
        // test the task report fetchers
        JobClient client = new JobClient(job);
        JobID jobid = ret.job.getID();
        TaskReport[] reports;
        reports = client.getSetupTaskReports(jobid);
        assertEquals("number of setups", 2, reports.length);
        reports = client.getMapTaskReports(jobid);
        assertEquals("number of maps", 1, reports.length);
        reports = client.getReduceTaskReports(jobid);
        assertEquals("number of reduces", 1, reports.length);
        reports = client.getCleanupTaskReports(jobid);
        assertEquals("number of cleanups", 2, reports.length);
        Counters counters = ret.job.getCounters();
        assertEquals("number of map inputs", 3, counters.getCounter(Task.Counter.MAP_INPUT_RECORDS));
        assertEquals("number of reduce outputs", 9, counters.getCounter(Task.Counter.REDUCE_OUTPUT_RECORDS));
        runCustomFormats(mr);
    } finally {
        if (mr != null) {
            mr.shutdown();
        }
    }
}
