protected void process(NodeFilter filter) throws ParserException {
    String url;
    int bookmark;
    NodeList list;
    NodeList robots;
    MetaTag robot;
    String content;
    File file;
    File dir;
    PrintWriter out;
    // get the next URL and add it to the done pile
    url = (String) mPages.remove(0);
    System.out.println("processing " + url);
    mFinished.add(url);
    try {
        bookmark = mPages.size();
        // fetch the page and gather the list of nodes
        mParser.setURL(url);
        try {
            list = new NodeList();
            for (NodeIterator e = mParser.elements(); e.hasMoreNodes(); ) // URL conversion occurs in the tags
            list.add(e.nextNode());
        } catch (EncodingChangeException ece) {
            // fix bug #998195 SiteCatpurer just crashed
            // try again with the encoding now set correctly
            // hopefully mPages, mImages, mCopied and mFinished won't be corrupted
            mParser.reset();
            list = new NodeList();
            for (NodeIterator e = mParser.elements(); e.hasMoreNodes(); ) list.add(e.nextNode());
        }
        // handle robots meta tag according to http://www.robotstxt.org/wc/meta-user.html
        // <meta name="robots" content="index,follow" />
        // <meta name="robots" content="noindex,nofollow" />
        robots = list.extractAllNodesThatMatch(new AndFilter(new NodeClassFilter(MetaTag.class), new HasAttributeFilter("name", "robots")), true);
        if (0 != robots.size()) {
            robot = (MetaTag) robots.elementAt(0);
            content = robot.getAttribute("content").toLowerCase();
            if ((-1 != content.indexOf("none")) || (-1 != content.indexOf("nofollow")))
                // reset mPages
                for (int i = bookmark; i < mPages.size(); i++) mPages.remove(i);
            if ((-1 != content.indexOf("none")) || (-1 != content.indexOf("noindex")))
                return;
        }
        if (null != filter)
            list.keepAllNodesThatMatch(filter, true);
        // save the page locally
        file = new File(getTarget(), makeLocalLink(url, ""));
        dir = file.getParentFile();
        if (!dir.exists())
            dir.mkdirs();
        else if (!dir.isDirectory()) {
            dir = new File(dir.getParentFile(), dir.getName() + ".content");
            if (!dir.exists())
                dir.mkdirs();
            file = new File(dir, file.getName());
        }
        try {
            out = new PrintWriter(new FileOutputStream(file));
            for (int i = 0; i < list.size(); i++) out.print(list.elementAt(i).toHtml());
            out.close();
        } catch (FileNotFoundException fnfe) {
            fnfe.printStackTrace();
        }
    } catch (ParserException pe) {
        String message;
        // this exception handling is suboptimal,
        // but it recognizes resources that aren't text/html
        message = pe.getMessage();
        if ((null != message) && (message.endsWith("does not contain text"))) {
            if (!mCopied.contains(url))
                if (!mImages.contains(url))
                    mImages.add(url);
            mFinished.remove(url);
        } else
            throw pe;
    }
}
