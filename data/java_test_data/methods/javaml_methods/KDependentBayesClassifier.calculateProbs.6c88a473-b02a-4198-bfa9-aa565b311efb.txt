protected HashMap<Object, Double> calculateProbs(Instance inst) {
    System.out.println("Start classification process");
    // classification process KDB, cfr. theory
    HashMap<Object, Double> out = new HashMap<Object, Double>();
    coverAbsentFeatures_And_fill_helpMap(inst);
    // fetch frequencies
    Hashtable<Integer, Hashtable<Double, ClassCounter>> featureName_HT = trainResult.getFeatureTable();
    double[] freq = trainResult.getClassFreqs().clone();
    // fetch dependencies for current working k value
    BayesNet BN = trainResult.getBayesNet(currentWorkingK).getBN();
    // get feature list
    Set<Integer> List = BN.getNodes();
    for (int k = 0; k < numClasses; k++) {
        Iterator itrtlc = List.iterator();
        double classScore = fnc.log2(freq[k] / numInstances);
        while (itrtlc.hasNext()) {
            int feature_current = (Integer) itrtlc.next();
            // for laplace
            int numValues = featureName_HT.get(feature_current).size();
            Vector<Integer> parents = BN.getNodeParents(feature_current);
            SortedMap<Integer, LinkedList> sMap = new TreeMap<Integer, LinkedList>();
            Vector<Integer> list_instanceIDs = retrieveInstanceIDList(feature_current, getInstValue(feature_current, inst), k);
            double numerator = list_instanceIDs.size();
            // will be overwritten if feature has parents in BN
            double denominator = freq[k];
            if (parents.size() > 0) {
                Vector<Integer> parentList_instanceIDs;
                Iterator it = parents.iterator();
                // so duplicate check algo can go faster
                if ((parents.size() > 3) && (numFeatures > 50)) {
                    while (it.hasNext()) {
                        int parent = (Integer) it.next();
                        int newsize;
                        newsize = retrieveInstanceIDList(parent, getInstValue(parent, inst), k).size();
                        if (!sMap.containsKey(newsize)) {
                            LinkedList<Integer> list = new LinkedList<Integer>();
                            list.add(parent);
                            sMap.put(newsize, list);
                        } else {
                            sMap.get(newsize).add(parent);
                        }
                    }
                    LinkedList<Integer> list2 = new LinkedList<Integer>();
                    for (int sc : sMap.keySet()) {
                        list2.addAll(sMap.get(sc));
                    }
                    // filled parent map
                    it = list2.iterator();
                }
                int parent = (Integer) it.next();
                parentList_instanceIDs = retrieveInstanceIDList(parent, getInstValue(parent, inst), k);
                // parents of current feature
                while (it.hasNext() && parentList_instanceIDs != null) {
                    parent = (Integer) it.next();
                    parentList_instanceIDs = fnc.cutVectorsSort(parentList_instanceIDs, retrieveInstanceIDList(parent, getInstValue(parent, inst), k));
                }
                Vector<Integer> newlist = null;
                denominator = parentList_instanceIDs.size();
                if (parentList_instanceIDs != null) {
                    newlist = fnc.cutVectorsSort(list_instanceIDs, parentList_instanceIDs);
                }
                numerator = newlist.size();
            }
            classScore += fnc.log2(((numerator + 1) / (denominator + numValues)));
        }
        out.put(classes[k], classScore);
    }
    out = calcFictionalChances(out);
    return out;
}
